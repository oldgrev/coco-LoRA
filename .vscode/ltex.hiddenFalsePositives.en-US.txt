{"rule":"UPPERCASE_SENTENCE_START","sentence":"^\\Qremember me\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\QCOmputed COntextualization for Low Rank Adaptation\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\QCan you do me a favour and just answer in one word for simple things like that?\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\QUse LoRA for behaviour.\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\QArbitrary point at which the front end decides to LoRA-tize the previous text, and then apply it to the LLM.\\E$"}
{"rule":"A_INFINITIVE","sentence":"^\\QMaybe the embeddings are included in the fine-tune.\\E$"}
{"rule":"CD_NN","sentence":"^\\QCurrently 10 epochs at 64 LoRA Rate, 128 LoRA Alpha, Learning rate 0.0001, 2 batch size, 256 cutoff, 0.05 LoRA dropout will teach the model the 2023 Oscar award winner for best actor, including movie.\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\Q☑ Test to see if LoRA can be micro trained in a useful way\n☒ Test to see if 4bit LoRA can be stacked with GPTQ in TextWebUI (not as 29/05/2023)\n☒ Test to see if 4bit LoRA can be stacked with JohnSmith in TextWebUI (not as 29/05/2023)\n☐ Test with GGML doesn't seem possible yet?\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\Q☐ Test with 8bit LoRA it feels like compromising\n☐ Develop an automatic workflow that can LoRA-tize a conversation and stack it\n☐ Develop a GUI for customizing the workflow (removing unwanted content by regenerating the LoRA containing it)\n☐ Develop the offload to another device workflow\n☐ Differentiate behaviours between \"Work Chatbot\", \"Personal Chatbot\", \"Instruct\"\n☐ Review QLoRA and see if it's a better fit.\\E$"}
{"rule":"CD_NN","sentence":"^\\QCurrently, 10 epochs at 64 LoRA Rate, 128 LoRA Alpha, Learning rate 0.0001, 2 batch size, 256 cutoff, 0.05 LoRA dropout will teach the model the 2023 Oscar award winner for best actor, including movie.\\E$"}
{"rule":"MORFOLOGIK_RULE_EN_US","sentence":"^\\Q☐ Test with 8bit LoRA it feels like compromising\n☐ Develop an automatic workflow that can LoRA-tize a conversation and stack it\n☐ Develop a GUI for customizing the workflow (removing unwanted content by regenerating the LoRA containing it)\n☐ Develop the 'offload to another device' workflow\n☐ Differentiate behaviours between \"Work Chatbot\", \"Personal Chatbot\", \"Instruct\"\n☐ Review QLoRA and see if it's a better fit.\\E$"}
